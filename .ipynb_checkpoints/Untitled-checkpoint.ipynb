{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a474c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 13:45:42.528 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Hari\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-06 13:45:42.531 No runtime found, using MemoryCacheStorageManager\n",
      "2025-07-06 13:45:42.534 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import concurrent.futures\n",
    "import itertools\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import io\n",
    "\n",
    "print(\"Code is running...\")\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Advanced Blend Optimizer\",\n",
    "    page_icon=\"🧪\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "st.title(\"🧪 Advanced Blend Optimizer\")\n",
    "st.markdown(\"Optimize chemical compound blends with AI-driven algorithms\")\n",
    "\n",
    "# Sidebar configuration\n",
    "st.sidebar.header(\"⚙️ Configuration\")\n",
    "\n",
    "# Cache data loading\n",
    "@st.cache_data\n",
    "def load_csv():\n",
    "    try:\n",
    "        compound_data = pd.read_csv(r\"C:\\Users\\Hari\\Desktop\\intership\\prototype\\compound_dataset_2000.csv\")\n",
    "        lot_compound = pd.read_csv(r\"C:\\Users\\Hari\\Desktop\\intership\\prototype\\compound_lots_dataset_2000.csv\")\n",
    "        return compound_data, lot_compound\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"CSV files not found. Please ensure compound_dataset_2000.csv and compound_lots_dataset_2000.csv are in the working directory.\")\n",
    "        return None, None\n",
    "\n",
    "# Load data\n",
    "compound_data, lot_data = load_csv()\n",
    "\n",
    "if compound_data is None:\n",
    "    st.stop()\n",
    "\n",
    "# Properties list\n",
    "properties = [\n",
    "    'Attrition resistance', 'Thermal Stability', 'Average particle size',\n",
    "    'Particle size distribution', 'density', 'rare earth oxides',\n",
    "    'catalyst surface area', 'micropore surface area', 'zeolite surface area',\n",
    "    'X-ray fluorescence'\n",
    "]\n",
    "\n",
    "# Generate cost column if not present\n",
    "if 'cost' not in compound_data.columns:\n",
    "    compound_data['cost'] = np.random.randint(100, 1000, len(compound_data))\n",
    "\n",
    "# Sidebar optimization settings\n",
    "st.sidebar.subheader(\"🔧 Optimization Settings\")\n",
    "\n",
    "# Performance optimization options\n",
    "use_pca = st.sidebar.checkbox(\"Use PCA for dimensionality reduction\", value=False)\n",
    "if use_pca:\n",
    "    n_components = st.sidebar.slider(\"PCA Components\", 5, 50, 20)\n",
    "\n",
    "pre_filter = st.sidebar.checkbox(\"Pre-filter top candidates\", value=True)\n",
    "if pre_filter:\n",
    "    top_n = st.sidebar.slider(\"Top N candidates\", 50, 500, 100)\n",
    "\n",
    "# Optimization algorithm selection\n",
    "algorithm = st.sidebar.selectbox(\n",
    "    \"Optimization Algorithm\",\n",
    "    [\"SLSQP\", \"Differential Evolution\", \"Multi-start SLSQP\"]\n",
    ")\n",
    "\n",
    "# Lambda (cost-accuracy tradeoff)\n",
    "lambda_val = st.sidebar.slider(\"λ (Cost vs Accuracy)\", 0.1, 100.0, 1.0, 0.1)\n",
    "\n",
    "# Phase selection\n",
    "phase = st.sidebar.selectbox(\"Optimization Phase\", [\"Ideal Compounds\", \"Real Lots\"])\n",
    "\n",
    "# Constraint management\n",
    "st.sidebar.subheader(\"🎯 Constraint Management\")\n",
    "max_reo = st.sidebar.slider(\"Max REO %\", 0.0, 5.0, 2.0, 0.1)\n",
    "exclude_compounds = st.sidebar.multiselect(\n",
    "    \"Exclude Compounds\", \n",
    "    compound_data['Compound Name'].tolist() if 'Compound Name' in compound_data.columns else []\n",
    ")\n",
    "\n",
    "# Main content area\n",
    "col1, col2 = st.columns([1, 1])\n",
    "\n",
    "with col1:\n",
    "    st.subheader(\"🎯 Target Properties\")\n",
    "    \n",
    "    # Allow user input for all target properties\n",
    "    target_dict = {}\n",
    "    default_values = [87.49, 885.21, 7.59, 1.7, 0.909, 0.78, 64.52, 87.96, 340.45, 0.7081]\n",
    "    \n",
    "    for i, prop in enumerate(properties):\n",
    "        with st.expander(f\"{prop}\"):\n",
    "            constraint_type = st.selectbox(f\"Constraint for {prop}:\", options=[\"=\", \">=\", \"<=\"], key=f\"constraint_{i}\")\n",
    "            value = st.number_input(f\"Target value for {prop}\", value=default_values[i], key=f\"value_{i}\")\n",
    "            target_dict[prop] = {\"type\": constraint_type, \"value\": value}\n",
    "\n",
    "with col2:\n",
    "    st.subheader(\"📊 Target Summary\")\n",
    "    target_df = pd.DataFrame.from_dict(target_dict, orient='index')\n",
    "    st.dataframe(target_df)\n",
    "\n",
    "# Enhanced blend error function\n",
    "def blend_error(weights, prop_matrix, constraint_dict, cost_vector, lam=1.0, property_stds=None):\n",
    "    \"\"\"Enhanced blend error function with normalization and proper constraint handling\"\"\"\n",
    "    blend = np.dot(weights, prop_matrix)\n",
    "    error = 0\n",
    "    \n",
    "    for i, prop in enumerate(properties):\n",
    "        if prop not in constraint_dict:\n",
    "            continue\n",
    "            \n",
    "        val = blend[i]\n",
    "        rule = constraint_dict[prop][\"type\"]\n",
    "        target = constraint_dict[prop][\"value\"]\n",
    "        \n",
    "        # Use property standard deviation for normalization\n",
    "        std = property_stds[i] if property_stds is not None else 1.0\n",
    "        \n",
    "        if rule == \"=\":\n",
    "            error += ((val - target) / std) ** 2\n",
    "        elif rule == \"<=\" and val > target:\n",
    "            error += ((val - target) / std) ** 2\n",
    "        elif rule == \">=\" and val < target:\n",
    "            error += ((val - target) / std) ** 2\n",
    "    \n",
    "    # Normalized cost term\n",
    "    cost = np.dot(weights, cost_vector)\n",
    "    max_cost = np.max(cost_vector)\n",
    "    normalized_cost = cost / max_cost\n",
    "    \n",
    "    return error + lam * normalized_cost\n",
    "\n",
    "# Performance optimization functions\n",
    "def apply_pca(data, n_components=20):\n",
    "    \"\"\"Apply PCA for dimensionality reduction\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_data = pca.fit_transform(scaled_data)\n",
    "    return reduced_data, pca, scaler\n",
    "\n",
    "def pre_filter_compounds(compound_data, target_dict, top_n=100):\n",
    "    \"\"\"Pre-filter compounds based on individual property matching\"\"\"\n",
    "    scores = []\n",
    "    prop_matrix = compound_data[properties].values\n",
    "    \n",
    "    for idx, row in enumerate(prop_matrix):\n",
    "        score = 0\n",
    "        for i, prop in enumerate(properties):\n",
    "            if prop in target_dict:\n",
    "                val = row[i]\n",
    "                target = target_dict[prop][\"value\"]\n",
    "                rule = target_dict[prop][\"type\"]\n",
    "                \n",
    "                if rule == \"=\":\n",
    "                    score += (val - target) ** 2\n",
    "                elif rule == \"<=\" and val > target:\n",
    "                    score += (val - target) ** 2\n",
    "                elif rule == \">=\" and val < target:\n",
    "                    score += (val - target) ** 2\n",
    "        \n",
    "        scores.append((idx, score))\n",
    "    \n",
    "    # Sort by score and take top N\n",
    "    scores.sort(key=lambda x: x[1])\n",
    "    top_indices = [idx for idx, _ in scores[:top_n]]\n",
    "    \n",
    "    return compound_data.iloc[top_indices].reset_index(drop=True)\n",
    "\n",
    "def multi_start_optimization(prop_matrix, constraint_dict, cost_vector, n_starts=5):\n",
    "    \"\"\"Multi-start optimization to escape local minima\"\"\"\n",
    "    best_result = None\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    n = len(prop_matrix)\n",
    "    bounds = [(0, 1)] * n\n",
    "    constraints = {\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1}\n",
    "    property_stds = np.std(prop_matrix, axis=0)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for start in range(n_starts):\n",
    "        # Random initialization\n",
    "        initial = np.random.dirichlet(np.ones(n))\n",
    "        \n",
    "        try:\n",
    "            res = minimize(\n",
    "                blend_error,\n",
    "                initial,\n",
    "                args=(prop_matrix, constraint_dict, cost_vector, lambda_val, property_stds),\n",
    "                method='SLSQP',\n",
    "                bounds=bounds,\n",
    "                constraints=[constraints],\n",
    "                options={'maxiter': 1000}\n",
    "            )\n",
    "            \n",
    "            if res.success and res.fun < best_loss:\n",
    "                best_loss = res.fun\n",
    "                best_result = res\n",
    "            \n",
    "            results.append(res)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return best_result, results\n",
    "\n",
    "# Optimization button\n",
    "if st.button(\"🚀 Optimize Blend\", type=\"primary\"):\n",
    "    \n",
    "    # Apply filters if enabled\n",
    "    working_data = compound_data.copy()\n",
    "    \n",
    "    # Exclude compounds\n",
    "    if exclude_compounds:\n",
    "        working_data = working_data[~working_data['Compound Name'].isin(exclude_compounds)]\n",
    "    \n",
    "    # Apply REO constraint\n",
    "    if 'rare earth oxides' in working_data.columns:\n",
    "        working_data = working_data[working_data['rare earth oxides'] <= max_reo]\n",
    "    \n",
    "    # Pre-filter compounds\n",
    "    if pre_filter:\n",
    "        working_data = pre_filter_compounds(working_data, target_dict, top_n)\n",
    "        st.info(f\"Pre-filtered to {len(working_data)} compounds\")\n",
    "    \n",
    "    # Prepare matrices\n",
    "    prop_matrix = working_data[properties].values\n",
    "    cost_vector = working_data['cost'].values\n",
    "    n = len(working_data)\n",
    "    \n",
    "    if n == 0:\n",
    "        st.error(\"No compounds available after filtering!\")\n",
    "        st.stop()\n",
    "    \n",
    "    # Apply PCA if enabled\n",
    "    if use_pca and len(properties) > n_components:\n",
    "        reduced_props, pca, scaler = apply_pca(prop_matrix, n_components)\n",
    "        st.info(f\"Applied PCA: {len(properties)} → {n_components} dimensions\")\n",
    "    \n",
    "    # Progress bar\n",
    "    progress_bar = st.progress(0)\n",
    "    status_text = st.empty()\n",
    "    \n",
    "    # Optimization\n",
    "    start_time = time.time()\n",
    "    \n",
    "    bounds = [(0, 1)] * n\n",
    "    constraints = {\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1}\n",
    "    property_stds = np.std(prop_matrix, axis=0)\n",
    "    \n",
    "    if algorithm == \"SLSQP\":\n",
    "        status_text.text(\"Running SLSQP optimization...\")\n",
    "        progress_bar.progress(0.5)\n",
    "        \n",
    "        initial = np.ones(n) / n\n",
    "        res = minimize(\n",
    "            blend_error,\n",
    "            initial,\n",
    "            args=(prop_matrix, target_dict, cost_vector, lambda_val, property_stds),\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=[constraints],\n",
    "            options={'maxiter': 1000}\n",
    "        )\n",
    "        \n",
    "    elif algorithm == \"Differential Evolution\":\n",
    "        status_text.text(\"Running Differential Evolution...\")\n",
    "        progress_bar.progress(0.5)\n",
    "        \n",
    "        def de_objective(weights):\n",
    "            return blend_error(weights, prop_matrix, target_dict, cost_vector, lambda_val, property_stds)\n",
    "        \n",
    "        res = differential_evolution(\n",
    "            de_objective,\n",
    "            bounds,\n",
    "            constraints=[constraints],\n",
    "            maxiter=100,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "    elif algorithm == \"Multi-start SLSQP\":\n",
    "        status_text.text(\"Running Multi-start SLSQP...\")\n",
    "        progress_bar.progress(0.5)\n",
    "        \n",
    "        res, all_results = multi_start_optimization(prop_matrix, target_dict, cost_vector, n_starts=5)\n",
    "    \n",
    "    progress_bar.progress(1.0)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    if res and res.success:\n",
    "        st.success(f\"Optimization completed in {end_time - start_time:.2f} seconds\")\n",
    "        st.write(f\"**Final loss value:** {res.fun:.6f}\")\n",
    "        \n",
    "        # Results analysis\n",
    "        working_data['Weight'] = np.round(res.x, 6)\n",
    "        selected = working_data[working_data['Weight'] > 0.001].copy()\n",
    "        \n",
    "        # Display results\n",
    "        col1, col2 = st.columns([1, 1])\n",
    "        \n",
    "        with col1:\n",
    "            st.subheader(\"📋 Selected Compounds\")\n",
    "            display_cols = ['Compound Name', 'Weight', 'cost'] if 'Compound Name' in selected.columns else ['Weight', 'cost']\n",
    "            st.dataframe(selected[display_cols])\n",
    "            \n",
    "            # Total cost\n",
    "            total_cost = np.sum(selected['Weight'] * selected['cost'])\n",
    "            st.metric(\"Total Blend Cost\", f\"${total_cost:.2f}\")\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"🎯 Blend vs Target Properties\")\n",
    "            blend_props = np.dot(res.x, prop_matrix)\n",
    "            \n",
    "            comparison_df = pd.DataFrame({\n",
    "                'Property': properties,\n",
    "                'Target': [target_dict[p]['value'] for p in properties],\n",
    "                'Blend': blend_props,\n",
    "                'Constraint': [target_dict[p]['type'] for p in properties]\n",
    "            })\n",
    "            \n",
    "            comparison_df['Deviation'] = comparison_df['Blend'] - comparison_df['Target']\n",
    "            comparison_df['Deviation %'] = (comparison_df['Deviation'] / comparison_df['Target']) * 100\n",
    "            \n",
    "            st.dataframe(comparison_df)\n",
    "        \n",
    "        # Visualizations\n",
    "        st.subheader(\"📊 Visualization\")\n",
    "        \n",
    "        # Radar chart for property comparison\n",
    "        fig_radar = go.Figure()\n",
    "        \n",
    "        angles = np.linspace(0, 2 * np.pi, len(properties), endpoint=False)\n",
    "        \n",
    "        # Normalize values for radar chart\n",
    "        target_vals = [target_dict[p]['value'] for p in properties]\n",
    "        blend_vals = blend_props\n",
    "        \n",
    "        # Normalize to 0-1 scale for visualization\n",
    "        max_vals = np.maximum(target_vals, blend_vals)\n",
    "        norm_target = np.array(target_vals) / max_vals\n",
    "        norm_blend = np.array(blend_vals) / max_vals\n",
    "        \n",
    "        fig_radar.add_trace(go.Scatterpolar(\n",
    "            r=norm_target,\n",
    "            theta=properties,\n",
    "            fill='toself',\n",
    "            name='Target',\n",
    "            line_color='blue'\n",
    "        ))\n",
    "        \n",
    "        fig_radar.add_trace(go.Scatterpolar(\n",
    "            r=norm_blend,\n",
    "            theta=properties,\n",
    "            fill='toself',\n",
    "            name='Blend',\n",
    "            line_color='red'\n",
    "        ))\n",
    "        \n",
    "        fig_radar.update_layout(\n",
    "            polar=dict(\n",
    "                radialaxis=dict(visible=True, range=[0, 1])\n",
    "            ),\n",
    "            showlegend=True,\n",
    "            title=\"Property Comparison: Target vs Blend\"\n",
    "        )\n",
    "        \n",
    "        st.plotly_chart(fig_radar, use_container_width=True)\n",
    "        \n",
    "        # Bar chart for compound weights\n",
    "        if len(selected) > 0:\n",
    "            fig_bar = px.bar(\n",
    "                selected,\n",
    "                x='Compound Name' if 'Compound Name' in selected.columns else selected.index,\n",
    "                y='Weight',\n",
    "                title=\"Compound Weights in Optimal Blend\",\n",
    "                color='cost',\n",
    "                color_continuous_scale='Viridis'\n",
    "            )\n",
    "            st.plotly_chart(fig_bar, use_container_width=True)\n",
    "        \n",
    "        # Export functionality\n",
    "        st.subheader(\"📥 Export Results\")\n",
    "        \n",
    "        col1, col2 = st.columns([1, 1])\n",
    "        \n",
    "        with col1:\n",
    "            # Export selected compounds\n",
    "            csv_compounds = selected.to_csv(index=False)\n",
    "            st.download_button(\n",
    "                label=\"Download Selected Compounds\",\n",
    "                data=csv_compounds,\n",
    "                file_name=\"selected_compounds.csv\",\n",
    "                mime=\"text/csv\"\n",
    "            )\n",
    "        \n",
    "        with col2:\n",
    "            # Export blend properties\n",
    "            csv_properties = comparison_df.to_csv(index=False)\n",
    "            st.download_button(\n",
    "                label=\"Download Blend Properties\",\n",
    "                data=csv_properties,\n",
    "                file_name=\"blend_properties.csv\",\n",
    "                mime=\"text/csv\"\n",
    "            )\n",
    "        \n",
    "        # Phase 2: Lot-level optimization\n",
    "        if phase == \"Real Lots\" and lot_data is not None:\n",
    "            st.subheader(\"🏭 Phase 2: Lot-Level Optimization\")\n",
    "            \n",
    "            if st.button(\"Optimize with Real Lots\"):\n",
    "                # Filter lots for selected compounds\n",
    "                selected_compound_names = selected['Compound Name'].tolist() if 'Compound Name' in selected.columns else []\n",
    "                \n",
    "                if 'Compound Name' in lot_data.columns:\n",
    "                    available_lots = lot_data[lot_data['Compound Name'].isin(selected_compound_names)]\n",
    "                    \n",
    "                    if len(available_lots) > 0:\n",
    "                        st.info(f\"Found {len(available_lots)} lots for selected compounds\")\n",
    "                        \n",
    "                        # Re-run optimization with lot data\n",
    "                        lot_prop_matrix = available_lots[properties].values\n",
    "                        lot_cost_vector = available_lots['cost'].values if 'cost' in available_lots.columns else np.random.randint(100, 1000, len(available_lots))\n",
    "                        \n",
    "                        lot_n = len(available_lots)\n",
    "                        lot_bounds = [(0, 1)] * lot_n\n",
    "                        lot_constraints = {\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1}\n",
    "                        lot_initial = np.ones(lot_n) / lot_n\n",
    "                        \n",
    "                        lot_res = minimize(\n",
    "                            blend_error,\n",
    "                            lot_initial,\n",
    "                            args=(lot_prop_matrix, target_dict, lot_cost_vector, lambda_val, np.std(lot_prop_matrix, axis=0)),\n",
    "                            method='SLSQP',\n",
    "                            bounds=lot_bounds,\n",
    "                            constraints=[lot_constraints]\n",
    "                        )\n",
    "                        \n",
    "                        if lot_res.success:\n",
    "                            st.success(\"Lot-level optimization completed!\")\n",
    "                            \n",
    "                            available_lots['Weight'] = np.round(lot_res.x, 6)\n",
    "                            selected_lots = available_lots[available_lots['Weight'] > 0.001]\n",
    "                            \n",
    "                            st.subheader(\"Selected Lots\")\n",
    "                            lot_display_cols = ['Compound Name', 'Lot ID', 'Weight', 'cost'] if all(col in selected_lots.columns for col in ['Compound Name', 'Lot ID']) else ['Weight', 'cost']\n",
    "                            st.dataframe(selected_lots[lot_display_cols])\n",
    "                        else:\n",
    "                            st.error(\"Lot-level optimization failed\")\n",
    "                    else:\n",
    "                        st.warning(\"No lots available for selected compounds\")\n",
    "                else:\n",
    "                    st.warning(\"Lot data doesn't contain compound names for matching\")\n",
    "    \n",
    "    else:\n",
    "        st.error(\"Optimization failed! Try different settings or check your constraints.\")\n",
    "    \n",
    "    status_text.empty()\n",
    "    progress_bar.empty()\n",
    "\n",
    "# Advanced features section\n",
    "st.subheader(\"🔬 Advanced Features\")\n",
    "\n",
    "with st.expander(\"Performance Metrics\"):\n",
    "    if compound_data is not None:\n",
    "        st.write(\"**Dataset Information:**\")\n",
    "        st.write(f\"- Total compounds: {len(compound_data)}\")\n",
    "        st.write(f\"- Properties: {len(properties)}\")\n",
    "        st.write(f\"- Memory usage: {compound_data.memory_usage().sum() / 1024:.2f} KB\")\n",
    "        \n",
    "        st.write(\"**Property Statistics:**\")\n",
    "        st.dataframe(compound_data[properties].describe())\n",
    "\n",
    "with st.expander(\"Algorithm Comparison\"):\n",
    "    st.write(\"\"\"\n",
    "    **Algorithm Recommendations:**\n",
    "    - **SLSQP**: Fast, good for local optimization\n",
    "    - **Differential Evolution**: Global optimizer, slower but more robust\n",
    "    - **Multi-start SLSQP**: Balance between speed and global search\n",
    "    \"\"\")\n",
    "\n",
    "with st.expander(\"Constraint Violations\"):\n",
    "    st.write(\"Check this section after optimization to see any constraint violations\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"**Advanced Blend Optimizer** - Powered by SciPy, Streamlit, and Plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4624b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
